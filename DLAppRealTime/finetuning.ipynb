{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateOptionError",
     "evalue": "While reading from 'config.ini' [line 18]: option 'model_name' in section 'DEFAULT' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateOptionError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfigparser\u001b[39;00m\n\u001b[0;32m     13\u001b[0m config_ini \u001b[38;5;241m=\u001b[39m configparser\u001b[38;5;241m.\u001b[39mConfigParser()\n\u001b[1;32m---> 14\u001b[0m \u001b[43mconfig_ini\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.ini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\configparser.py:713\u001b[0m, in \u001b[0;36mRawConfigParser.read\u001b[1;34m(self, filenames, encoding)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, encoding\u001b[38;5;241m=\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m--> 713\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\configparser.py:1112\u001b[0m, in \u001b[0;36mRawConfigParser._read\u001b[1;34m(self, fp, fpname)\u001b[0m\n\u001b[0;32m   1109\u001b[0m optname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptionxform(optname\u001b[38;5;241m.\u001b[39mrstrip())\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strict \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1111\u001b[0m     (sectname, optname) \u001b[38;5;129;01min\u001b[39;00m elements_added):\n\u001b[1;32m-> 1112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DuplicateOptionError(sectname, optname,\n\u001b[0;32m   1113\u001b[0m                                fpname, lineno)\n\u001b[0;32m   1114\u001b[0m elements_added\u001b[38;5;241m.\u001b[39madd((sectname, optname))\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# This check is fine because the OPTCRE cannot\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;66;03m# match if it would set optval to None\u001b[39;00m\n",
      "\u001b[1;31mDuplicateOptionError\u001b[0m: While reading from 'config.ini' [line 18]: option 'model_name' in section 'DEFAULT' already exists"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoFeatureExtractor,\n",
    "    AutoModelForAudioClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AwqConfig,\n",
    ")\n",
    "from datasets import Audio, ClassLabel, load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "import configparser\n",
    "config_ini = configparser.ConfigParser()\n",
    "config_ini.read(\"config.ini\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 160/160 [00:00<00:00, 113340.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'label'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_names = [\n",
    "    \"pingpong\",\n",
    "    \"caughing\",\n",
    "    \"clapping\",\n",
    "    \"silence\",\n",
    "]\n",
    "\n",
    "# https://huggingface.co/docs/datasets/audio_load\n",
    "# metadata.csv, file1.wav, file2.wav....\n",
    "audio_dataset = load_dataset(\n",
    "    \"audiofolder\",\n",
    "    data_dir=\"./data/test/\",\n",
    "    # data_dir=\"./data/UrbanSound8K/audio\",\n",
    ")\n",
    "# audio_dataset = load_dataset(\"marsyas/gtzan\", \"all\")\n",
    "audio_dataset\n",
    "# audio_dataset[\"train\"][0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to train and test\n",
    "audio_dataset = audio_dataset[\"train\"].train_test_split(seed=42, shuffle=True, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'label'],\n",
       "        num_rows: 144\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'label'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_label = ClassLabel(num_classes=len(label_names), names=label_names)\n",
    "audio_dataset = audio_dataset.cast_column(\"label\", class_label)\n",
    "audio_dataset[\"train\"].features\n",
    "audio_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2label_fn = audio_dataset[\"train\"].features[\"class\"].int2str\n",
    "id2label_fn = audio_dataset[\"train\"].features[\"label\"].int2str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessor_config.json: 100%|██████████| 215/215 [00:00<?, ?B/s] \n",
      "c:\\GitHub\\SED_sandbox\\DLAppRealTime\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yus98\\.cache\\huggingface\\hub\\models--dima806--music_genres_classification. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  class HfFileMetadata:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model\n",
    "model_id = config_ini['DEFAULT']['model_id_for_finetuneing']\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id,\n",
    "    do_normalize=True,\n",
    ")\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'C:/GitHub/SED_sandbox/DLAppRealTime/data/test/0_pingpong/ball_racket-32.wav',\n",
       " 'array': array([ 0.00305176,  0.00405884,  0.00286865, ..., -0.00485229,\n",
       "        -0.0043335 , -0.00323486]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sampling rate of dataset to 16k\n",
    "audio_dataset = audio_dataset.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
    "audio_dataset[\"train\"][0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 144/144 [00:00<00:00, 202.26 examples/s]\n",
      "Map: 100%|██████████| 16/16 [00:00<00:00, 172.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_values'],\n",
       "        num_rows: 144\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_values'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess dataset for adapting model\n",
    "# according to: https://github.com/karolpiczak/ESC-50\n",
    "# 学習する音データの長さ\n",
    "max_duration = 1\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=feature_extractor.sampling_rate,\n",
    "        max_length=int(feature_extractor.sampling_rate * max_duration),\n",
    "        truncation=True,\n",
    "        # return_attention_mask=False,\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "audio_dataset_encoded = audio_dataset.map(\n",
    "    preprocess_function,\n",
    "    remove_columns=[\"audio\"],\n",
    "    # remove_columns=[\"audio\", \"classID\"],\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    num_proc=1,\n",
    ")\n",
    "# audio_dataset_encoded = audio_dataset_encoded.rename_column(\"class\", \"label\")\n",
    "audio_dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 2.51k/2.51k [00:00<?, ?B/s]\n",
      "model.safetensors: 100%|██████████| 378M/378M [00:33<00:00, 11.3MB/s]\n",
      "Some weights of the model checkpoint at dima806/music_genres_classification were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at dima806/music_genres_classification and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at dima806/music_genres_classification and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([10]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([10, 256]) in the checkpoint and torch.Size([4, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# define label and model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "id2label = {str(i): id2label_fn(i) for i in range(len(audio_dataset_encoded[\"train\"].features[\"label\"].names))}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=num_labels,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    # torch_dtype=torch.float16,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training arguments\n",
    "model_name = model_id.split(\"/\")[-1]\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "num_train_epochs = 10\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f\"./model/pingpong-{model_name}-finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True,\n",
    "    hub_token=\"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\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=audio_dataset_encoded[\"train\"].with_format(\"torch\"),\n",
    "    eval_dataset=audio_dataset_encoded[\"test\"].with_format(\"torch\"),\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:28<?, ?it/s]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4434, 'learning_rate': 1.1111111111111112e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:28<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3582, 'learning_rate': 1.9444444444444445e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/180 [00:01<00:17,  9.60it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:29<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3156, 'learning_rate': 3.055555555555556e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      "  0%|          | 0/180 [07:29<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2557373046875, 'eval_accuracy': 0.375, 'eval_runtime': 0.0844, 'eval_samples_per_second': 189.52, 'eval_steps_per_second': 23.69, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:31<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2382, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 22/180 [00:04<00:41,  3.79it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:32<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1712, 'learning_rate': 4.9074074074074075e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 27/180 [00:04<00:20,  7.39it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:32<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1268, 'learning_rate': 4.7530864197530866e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 32/180 [00:05<00:16,  9.16it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:33<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1418, 'learning_rate': 4.5987654320987656e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      "  0%|          | 0/180 [07:33<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.960784912109375, 'eval_accuracy': 0.625, 'eval_runtime': 0.1041, 'eval_samples_per_second': 153.705, 'eval_steps_per_second': 19.213, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:35<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0179, 'learning_rate': 4.4444444444444447e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:35<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9313, 'learning_rate': 4.290123456790124e-05, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 47/180 [00:08<00:16,  8.18it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:36<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9312, 'learning_rate': 4.135802469135803e-05, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      "  0%|          | 0/180 [07:36<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8342742919921875, 'eval_accuracy': 0.625, 'eval_runtime': 0.0842, 'eval_samples_per_second': 189.931, 'eval_steps_per_second': 23.741, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:37<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.964, 'learning_rate': 3.981481481481482e-05, 'epoch': 3.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:38<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.783, 'learning_rate': 3.82716049382716e-05, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:39<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6839, 'learning_rate': 3.67283950617284e-05, 'epoch': 3.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:39<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6728, 'learning_rate': 3.518518518518519e-05, 'epoch': 3.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 72/180 [00:12<00:12,  8.83it/s]\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      "  0%|          | 0/180 [07:40<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6115798950195312, 'eval_accuracy': 0.9375, 'eval_runtime': 0.081, 'eval_samples_per_second': 197.495, 'eval_steps_per_second': 24.687, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:41<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5707, 'learning_rate': 3.364197530864198e-05, 'epoch': 4.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:42<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6076, 'learning_rate': 3.209876543209876e-05, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 82/180 [00:14<00:12,  7.64it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:42<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6148, 'learning_rate': 3.055555555555556e-05, 'epoch': 4.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 87/180 [00:15<00:10,  9.09it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:43<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7242, 'learning_rate': 2.9320987654320992e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                \n",
      "  0%|          | 0/180 [07:43<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6493301391601562, 'eval_accuracy': 0.8125, 'eval_runtime': 0.0711, 'eval_samples_per_second': 224.928, 'eval_steps_per_second': 28.116, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:45<?, ?it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5649, 'learning_rate': 2.777777777777778e-05, 'epoch': 5.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 97/180 [00:17<00:13,  6.00it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:45<?, ?it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5224, 'learning_rate': 2.623456790123457e-05, 'epoch': 5.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 102/180 [00:18<00:09,  8.46it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:46<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5707, 'learning_rate': 2.4691358024691357e-05, 'epoch': 5.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      "  0%|          | 0/180 [07:46<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5224800109863281, 'eval_accuracy': 0.875, 'eval_runtime': 0.0868, 'eval_samples_per_second': 184.306, 'eval_steps_per_second': 23.038, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:47<?, ?it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4865, 'learning_rate': 2.314814814814815e-05, 'epoch': 6.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 112/180 [00:20<00:15,  4.31it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:48<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4902, 'learning_rate': 2.1604938271604937e-05, 'epoch': 6.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:49<?, ?it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3766, 'learning_rate': 2.006172839506173e-05, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 122/180 [00:21<00:06,  8.84it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:49<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3726, 'learning_rate': 1.8518518518518518e-05, 'epoch': 6.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      "  0%|          | 0/180 [07:49<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2706298828125, 'eval_accuracy': 1.0, 'eval_runtime': 0.0863, 'eval_samples_per_second': 185.502, 'eval_steps_per_second': 23.188, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:51<?, ?it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5325, 'learning_rate': 1.697530864197531e-05, 'epoch': 7.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 132/180 [00:24<00:08,  5.89it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:51<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4047, 'learning_rate': 1.54320987654321e-05, 'epoch': 7.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:52<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3227, 'learning_rate': 1.388888888888889e-05, 'epoch': 7.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      "  0%|          | 0/180 [07:52<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3758735656738281, 'eval_accuracy': 0.9375, 'eval_runtime': 0.1014, 'eval_samples_per_second': 157.78, 'eval_steps_per_second': 19.723, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:54<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3792, 'learning_rate': 1.2345679012345678e-05, 'epoch': 8.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:54<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2411, 'learning_rate': 1.0802469135802469e-05, 'epoch': 8.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:55<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3123, 'learning_rate': 9.259259259259259e-06, 'epoch': 8.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:55<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1951, 'learning_rate': 7.71604938271605e-06, 'epoch': 8.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      "  0%|          | 0/180 [07:56<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1656341552734375, 'eval_accuracy': 1.0, 'eval_runtime': 0.0776, 'eval_samples_per_second': 206.265, 'eval_steps_per_second': 25.783, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:57<?, ?it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1958, 'learning_rate': 6.172839506172839e-06, 'epoch': 9.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 167/180 [00:30<00:02,  5.24it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:58<?, ?it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2469, 'learning_rate': 4.6296296296296296e-06, 'epoch': 9.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 172/180 [00:30<00:00,  8.21it/s]\u001b[A\n",
      "  0%|          | 0/180 [07:58<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1863, 'learning_rate': 3.0864197530864196e-06, 'epoch': 9.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/180 [07:59<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1796, 'learning_rate': 1.5432098765432098e-06, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                               \n",
      "                                                 \n",
      "  0%|          | 0/180 [07:59<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14742469787597656, 'eval_accuracy': 1.0, 'eval_runtime': 0.0735, 'eval_samples_per_second': 217.636, 'eval_steps_per_second': 27.204, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 180/180 [00:33<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 33.2384, 'train_samples_per_second': 43.323, 'train_steps_per_second': 5.415, 'train_loss': 0.6632374657524956, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=180, training_loss=0.6632374657524956, metrics={'train_runtime': 33.2384, 'train_samples_per_second': 43.323, 'train_steps_per_second': 5.415, 'train_loss': 0.6632374657524956, 'epoch': 10.0})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
